{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PRML_midterm_2021_statement.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqxPT5qD07ZunEZl692M+P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raulbenitez/AIHEART/blob/main/PRML_midterm_2021_statement_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AR3T0tKO9Iu"
      },
      "source": [
        "# Pattern Recognition and Machine Learning\n",
        "Partial exam, April 16, 2021\n",
        "\n",
        "\n",
        "The questions and exercises are described in this Python notebook. Please include the necessary text and code cells to answer the questions and upload the interactive Python notebook to the corresponding task in the ATENEA digital campus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GldIVtDPhUm"
      },
      "source": [
        "## **Question 1** (2 points):\n",
        "\n",
        "Imagine we have a complex data base with elements belonging to two classes distributed in 3 bubbles in a two dimensional space.\n",
        "\n",
        "Describe a couple of strategies to find a Neural Network model to solve this classification problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv5MAso0PlNZ"
      },
      "source": [
        "Answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-nFyglMPnE-"
      },
      "source": [
        "## **Question 2** (2 points): \n",
        "\n",
        "Describe what is a parsimony index and how can we use it in the context of data clustering. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpsE5lWt8sMf"
      },
      "source": [
        "Answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA-_85Y8Ptwg"
      },
      "source": [
        "## Exercise 1 (6 points): \n",
        "\n",
        "\n",
        "The exercise will be developed using one of the following 37 databases from from he plotly sample datasets: \n",
        "\n",
        "https://plotly.github.io/datasets/\n",
        "\n",
        "1.\tWalmart store openings\n",
        "2.\t2010 alchohol consumption by country X \n",
        "3.\t2011 February AA flight paths\n",
        "4.\t2011 February US airport traffic\n",
        "5.\t2011 US agriculture exports\n",
        "6.\t2014 Apple stock X \n",
        "7.\t2015 Shooting Incidents X \n",
        "8.\t2014 ebola X \n",
        "9.\t2014 US cities population\n",
        "10.\t2014 US states population X\n",
        "11.\t2014 world GDP X\n",
        "12.\t2015 precipitation\n",
        "13.\tAlpha shapes X \n",
        "14.\tGrouped bar charts with Excel X \n",
        "15.\tBubble charts with Excel X\n",
        "16.\tThree Y axes with Excel X \n",
        "17.\tDot plot with Excel X \n",
        "18.\tGapminder data\n",
        "19.\tGlobe contours X \n",
        "20.\tInset plot\n",
        "21.\tText scatter charts X\n",
        "22.\tLaTeX typesetting X \n",
        "23.\tNYC Uber rides\n",
        "24.\tOnline dating (multiple_y_axis)\n",
        "25.\tOKCupid compatibility by religion X \n",
        "26.\tPareto chart X \n",
        "27.\tSchool earnings\n",
        "28.\tShaded regions X \n",
        "29.\tSpectral\n",
        "30.\tPhoton density subplot\n",
        "31.\tClimate change subplot\n",
        "32.\tTime series with error bars\n",
        "33.\tTime series dataframe\n",
        "34.\tVolcano\n",
        "35.\tWind rose\n",
        "36.\tWind speed\n",
        "37.\tProstate cancer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_uCMN9HjnzU"
      },
      "source": [
        "Each student will be randomly assigned one of the databases by executing the code in the next code cell. The input parameter are the first three digits of your ID number (NIF, NIE or passport). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJV628oCQKdM",
        "outputId": "8dd97dea-8e32-4346-ab49-708aabcb2734"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input = 437 # put here the three fist digits of your ID number\n",
        "np.random.seed(input)\n",
        "ind = np.random.randint(38)\n",
        "print('You should work with database number {}'.format(ind))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You should work with database number 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj7mbJV1c5nc"
      },
      "source": [
        "You can either download the file or load the data by  accessing the raw file from the github repository https://github.com/plotly/datasets. For instance, to load the the first dataset in a pandas dataframe we would execute (path can be obtained by accessing the file from the GitHub and clicking the raw button):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "whZt8K_4SG0n",
        "outputId": "fd442a4d-5257-4245-854d-9f6af5cc0c76"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/1962_2006_walmart_store_openings.csv')\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>storenum</th>\n",
              "      <th>OPENDATE</th>\n",
              "      <th>date_super</th>\n",
              "      <th>conversion</th>\n",
              "      <th>st</th>\n",
              "      <th>county</th>\n",
              "      <th>STREETADDR</th>\n",
              "      <th>STRCITY</th>\n",
              "      <th>STRSTATE</th>\n",
              "      <th>ZIPCODE</th>\n",
              "      <th>type_store</th>\n",
              "      <th>LAT</th>\n",
              "      <th>LON</th>\n",
              "      <th>MONTH</th>\n",
              "      <th>DAY</th>\n",
              "      <th>YEAR</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>7/1/62</td>\n",
              "      <td>3/1/97</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2110 WEST WALNUT</td>\n",
              "      <td>Rogers</td>\n",
              "      <td>AR</td>\n",
              "      <td>72756</td>\n",
              "      <td>Supercenter</td>\n",
              "      <td>36.342235</td>\n",
              "      <td>-94.07141</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>8/1/64</td>\n",
              "      <td>3/1/96</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>1417 HWY 62/65 N</td>\n",
              "      <td>Harrison</td>\n",
              "      <td>AR</td>\n",
              "      <td>72601</td>\n",
              "      <td>Supercenter</td>\n",
              "      <td>36.236984</td>\n",
              "      <td>-93.09345</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>8/1/65</td>\n",
              "      <td>3/1/02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>2901 HWY 412 EAST</td>\n",
              "      <td>Siloam Springs</td>\n",
              "      <td>AR</td>\n",
              "      <td>72761</td>\n",
              "      <td>Supercenter</td>\n",
              "      <td>36.179905</td>\n",
              "      <td>-94.50208</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>10/1/67</td>\n",
              "      <td>3/1/93</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>29</td>\n",
              "      <td>1621 NORTH BUSINESS 9</td>\n",
              "      <td>Morrilton</td>\n",
              "      <td>AR</td>\n",
              "      <td>72110</td>\n",
              "      <td>Supercenter</td>\n",
              "      <td>35.156491</td>\n",
              "      <td>-92.75858</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>10/1/67</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>119</td>\n",
              "      <td>3801 CAMP ROBINSON RD.</td>\n",
              "      <td>North Little Rock</td>\n",
              "      <td>AR</td>\n",
              "      <td>72118</td>\n",
              "      <td>Wal-Mart</td>\n",
              "      <td>34.813269</td>\n",
              "      <td>-92.30229</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>7/1/68</td>\n",
              "      <td>3/1/98</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40</td>\n",
              "      <td>21</td>\n",
              "      <td>2020 SOUTH MUSKOGEE</td>\n",
              "      <td>Tahlequah</td>\n",
              "      <td>OK</td>\n",
              "      <td>74464</td>\n",
              "      <td>Supercenter</td>\n",
              "      <td>35.923658</td>\n",
              "      <td>-94.97185</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13</td>\n",
              "      <td>11/1/68</td>\n",
              "      <td>3/1/96</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29</td>\n",
              "      <td>97</td>\n",
              "      <td>2705 GRAND AVE</td>\n",
              "      <td>Carthage</td>\n",
              "      <td>MO</td>\n",
              "      <td>64836</td>\n",
              "      <td>Supercenter</td>\n",
              "      <td>37.168985</td>\n",
              "      <td>-94.31164</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>12</td>\n",
              "      <td>7/1/68</td>\n",
              "      <td>3/1/94</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40</td>\n",
              "      <td>131</td>\n",
              "      <td>1500 LYNN RIGGS BLVD</td>\n",
              "      <td>Claremore</td>\n",
              "      <td>OK</td>\n",
              "      <td>74017</td>\n",
              "      <td>Supercenter</td>\n",
              "      <td>36.327143</td>\n",
              "      <td>-95.61192</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>1968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11</td>\n",
              "      <td>3/1/68</td>\n",
              "      <td>2/20/02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>65 WAL-MART DRIVE</td>\n",
              "      <td>Mountain Home</td>\n",
              "      <td>AR</td>\n",
              "      <td>72653</td>\n",
              "      <td>Supercenter</td>\n",
              "      <td>36.329026</td>\n",
              "      <td>-92.35781</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>3/1/68</td>\n",
              "      <td>3/1/00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29</td>\n",
              "      <td>143</td>\n",
              "      <td>1303 SOUTH MAIN</td>\n",
              "      <td>Sikeston</td>\n",
              "      <td>MO</td>\n",
              "      <td>63801</td>\n",
              "      <td>Supercenter</td>\n",
              "      <td>36.891163</td>\n",
              "      <td>-89.58355</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1968</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   storenum OPENDATE date_super  conversion  ...       LON  MONTH DAY  YEAR\n",
              "0         1   7/1/62     3/1/97         1.0  ... -94.07141      7   1  1962\n",
              "1         2   8/1/64     3/1/96         1.0  ... -93.09345      8   1  1964\n",
              "2         4   8/1/65     3/1/02         1.0  ... -94.50208      8   1  1965\n",
              "3         8  10/1/67     3/1/93         1.0  ... -92.75858     10   1  1967\n",
              "4         7  10/1/67        NaN         NaN  ... -92.30229     10   1  1967\n",
              "5        10   7/1/68     3/1/98         1.0  ... -94.97185      7   1  1968\n",
              "6        13  11/1/68     3/1/96         1.0  ... -94.31164     11   1  1968\n",
              "7        12   7/1/68     3/1/94         1.0  ... -95.61192      7   1  1968\n",
              "8        11   3/1/68    2/20/02         1.0  ... -92.35781      3   1  1968\n",
              "9         9   3/1/68     3/1/00         1.0  ... -89.58355      3   1  1968\n",
              "\n",
              "[10 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krrk0iEGrne0"
      },
      "source": [
        "In order to remove NaNs just execute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG6zPnOhruaP",
        "outputId": "3595de09-c6d3-4573-81af-e2e5195273c0"
      },
      "source": [
        "data_nonans = data.dropna() # remove observations with NaNs\n",
        "\n",
        "print('original data = {}'.format(data.shape))\n",
        "print('numerical data without NaNs = {}'.format(data_nonans.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original data = (2992, 16)\n",
            "numerical data without NaNs = (1946, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou1_aZklly9t"
      },
      "source": [
        "Answer the following questions by adding as many text and code cells as needed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP__qLApw-8L"
      },
      "source": [
        "### a) **Data handling** (2 points): \n",
        "Provide a description of the dataset combining written text, data handling with pandas and graphical representation of the data. You should cover aspects such as the presence of missing data, dimension of the dataset, types of variables, etc. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAq6WKP879EB"
      },
      "source": [
        "### b) **Dimensionality reduction** (2 points):\n",
        "\n",
        "Apply a PCA to your dataset. How many principal components are required to account for 90% of the data variability? Report the eigenvalues, eigenvectors and the projection of the data to the PCA space of reduced dimensionality. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnQ0HZ9H8efx"
      },
      "source": [
        "### c) **Clustering or Classification** (2 points): \n",
        "\n",
        "Choose **one** of the following depending on the nature of your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8tQYErMwq7D"
      },
      "source": [
        "#### **Clustering**: \n",
        "Cluster the data (numerical features) using k-means, agglomerative or a Gaussian mixture model. Justify the number of clusters selected, visualize the clustering and briefly comment the results. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTnTW7Ocws8x"
      },
      "source": [
        "#### **Probabilistic classifier**: \n",
        "Identify a variable in the dataset that can be used as class label for supervised classification. Randomly split the data in training and test subsets. Train a probabilistic classifier (LDA, QDA, Gaussian Naive Bayes) using the training subset. Report some basic performance evaluation measures using the test subset. "
      ]
    }
  ]
}